{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abe404b",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT to generate word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa604ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist:\n",
    "scratch_cache = \"/ocean/projects/mth250011p/smazioud/huggingface_cache\"\n",
    "os.makedirs(scratch_cache, exist_ok=True)\n",
    "\n",
    "# Force HuggingFace + PyTorch to store EVERYTHING there\n",
    "os.environ['HF_HOME'] = scratch_cache\n",
    "os.environ['TRANSFORMERS_CACHE'] = scratch_cache\n",
    "os.environ['HF_DATASETS_CACHE'] = scratch_cache\n",
    "os.environ['HF_MODULES_CACHE'] = scratch_cache\n",
    "os.environ['HF_METRICS_CACHE'] = scratch_cache\n",
    "os.environ['TORCH_HOME'] = scratch_cache\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "login()\n",
    "\n",
    "print(\"HF cache directory:\", scratch_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, BertModel\n",
    "from datasets import Dataset\n",
    "from fine_tune_bert import mask_tokens, train_bert, apply_lora_to_bert\n",
    "from data_cleaning import clean_data\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = \"/jet/home/smazioud/stat215a_final\"\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "raw_path = \"/ocean/projects/mth250011p/shared/215a/final_project/data/raw_text.pkl\"\n",
    "\n",
    "with open(raw_path, \"rb\") as f:\n",
    "    raw = pickle.load(f)\n",
    "\n",
    "story_texts, story_ids = clean_data(raw)\n",
    "print(f\"\\nNumber of stories: {len(story_texts)}\")\n",
    "print(f\"Example story ID: {story_ids[0]}\")\n",
    "print(f\"Example text (first 200 chars):\\n{story_texts[0][:200]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9824e",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "print(f\"Tokenizer loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca8458",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9589550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "max_seq_len = 128  # fixed window length for BERT\n",
    "\n",
    "all_input_ids = []\n",
    "all_attention_masks = []\n",
    "\n",
    "for text in story_texts:\n",
    "    # 1) Tokenize the full story into token IDs (no truncation, no padding)\n",
    "    token_ids = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=False,      # we don't want [CLS]/[SEP] repeated across chunks\n",
    "        return_attention_mask=False,\n",
    "        return_tensors=None,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # 2) Chunk into windows of length max_seq_len\n",
    "    for i in range(0, len(token_ids), max_seq_len):\n",
    "        chunk = token_ids[i:i + max_seq_len]\n",
    "\n",
    "        # 3) Pad each chunk up to max_seq_len\n",
    "        padded = tokenizer.pad(\n",
    "            {\"input_ids\": [chunk]},\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_seq_len,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        all_input_ids.append(padded[\"input_ids\"][0])          # (seq_len,)\n",
    "        all_attention_masks.append(padded[\"attention_mask\"][0])\n",
    "\n",
    "# 4) Stack into tensors\n",
    "input_ids = torch.stack(all_input_ids)         # (num_chunks, max_seq_len)\n",
    "attention_mask = torch.stack(all_attention_masks)\n",
    "\n",
    "print(\"Number of chunks:\", input_ids.shape[0])\n",
    "print(\"Sequence length:\", input_ids.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, input_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        assert input_ids.shape == attention_mask.shape\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }\n",
    "\n",
    "dataset = TextDataset(input_ids, attention_mask)\n",
    "\n",
    "# Simple train/val split\n",
    "val_frac = 0.2\n",
    "n_total = len(dataset)\n",
    "n_val = int(val_frac * n_total)\n",
    "n_train = n_total - n_val\n",
    "\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13478b66",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT, apply LORA\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "base_model = BertForMaskedLM.from_pretrained(model_name)\n",
    "base_model = base_model.to(DEVICE)\n",
    "\n",
    "print(f\"Base model parameters: {sum(p.numel() for p in base_model.parameters()):,}\")\n",
    "\n",
    "# Wrap with LoRA adapters\n",
    "lora_model = apply_lora_to_bert(base_model, r=8, alpha=16, dropout=0.1)\n",
    "lora_model = lora_model.to(DEVICE)\n",
    "\n",
    "print(f\"LoRA-wrapped model is on device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 5e-5\n",
    "\n",
    "trained_model = train_bert(\n",
    "    model=lora_model,\n",
    "    train_loader=train_loader,\n",
    "    tokenizer=tokenizer,\n",
    "    val_loader=val_loader,\n",
    "    epochs=epochs,\n",
    "    lr=lr,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "output_dir = Path(repo_root) / \"saved_models\" / \"bert_lora_finetuned\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "trained_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Fine-tuned LoRA model saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2346b2",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "output_dir = Path(repo_root) / \"saved_models\" / \"bert_lora_finetuned\"\n",
    "finetuned_bert = BertModel.from_pretrained(output_dir, output_hidden_states=True)\n",
    "finetuned_bert = finetuned_bert.to(DEVICE)\n",
    "finetuned_bert.eval()\n",
    "\n",
    "print(\"Loaded finetuned encoder for embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ec6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_word_embeddings_for_words(\n",
    "    words,\n",
    "    tokenizer,\n",
    "    model: BertModel,\n",
    "    device=DEVICE,\n",
    "    chunk_size: int = 256,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute word-level embeddings for a list of words using BERT.\n",
    "\n",
    "    - Tokenize with is_split_into_words=True\n",
    "    - Average subword token embeddings per word\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    T = len(words)\n",
    "    embs = np.zeros((T, hidden_dim), dtype=np.float32)\n",
    "\n",
    "    start = 0\n",
    "    with torch.no_grad():\n",
    "        while start < T:\n",
    "            end = min(start + chunk_size, T)\n",
    "            chunk_words = words[start:end]\n",
    "\n",
    "            enc = tokenizer(\n",
    "                chunk_words,\n",
    "                is_split_into_words=True,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model(**enc)\n",
    "            last_hidden = outputs.last_hidden_state.cpu()  # (1, L, H)\n",
    "\n",
    "            # Map tokens back to original word indices\n",
    "            word_ids = enc.word_ids(batch_index=0)\n",
    "            word_to_vecs = {}\n",
    "\n",
    "            for tok_idx, w_id in enumerate(word_ids):\n",
    "                if w_id is None:\n",
    "                    continue\n",
    "                word_to_vecs.setdefault(w_id, []).append(last_hidden[0, tok_idx].numpy())\n",
    "\n",
    "            # Average subword embeddings per word\n",
    "            for local_w_id, vecs in word_to_vecs.items():\n",
    "                global_w_id = start + local_w_id\n",
    "                if global_w_id < T:\n",
    "                    embs[global_w_id] = np.mean(vecs, axis=0)\n",
    "\n",
    "            start = end\n",
    "\n",
    "    return embs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = {}  # story_id -> dict\n",
    "\n",
    "for story_id, ds in raw.items():\n",
    "    words = ds.data               # list[str]\n",
    "    word_times = ds.data_times    # np.array, shape (T,)\n",
    "    tr_times = ds.tr_times        # np.array, shape (n_TR,)\n",
    "\n",
    "    print(f\"Processing story: {story_id}, #words = {len(words)}\")\n",
    "\n",
    "    embs = get_bert_word_embeddings_for_words(\n",
    "        words=words,\n",
    "        tokenizer=tokenizer,\n",
    "        model=finetuned_bert,\n",
    "        device=DEVICE,\n",
    "        chunk_size=256\n",
    "    )  # shape (T, 768)\n",
    "\n",
    "    print(\"  embeddings shape:\", embs.shape)\n",
    "\n",
    "    bert_embeddings[story_id] = {\n",
    "        \"words\": words,\n",
    "        \"word_times\": word_times,\n",
    "        \"tr_times\": tr_times,\n",
    "        \"embeddings\": embs,\n",
    "    }\n",
    "\n",
    "out_path = output_dir / \"bert_lora_finetuned_word_embeddings.pkl\"\n",
    "\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(bert_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817aab75",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ef090",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = Path(output_dir) / \"bert_lora_finetuned_word_embeddings.pkl\"\n",
    "\n",
    "with open(emb_path, \"rb\") as f:\n",
    "    bert_embeddings = pickle.load(f)\n",
    "\n",
    "first_sid = sorted(bert_embeddings.keys())[1]\n",
    "story_data = bert_embeddings[first_sid]\n",
    "\n",
    "embs = story_data[\"embeddings\"]   # shape (T, 768)\n",
    "words = story_data[\"words\"]       # list of T words\n",
    "print(first_sid, embs.shape)\n",
    "\n",
    "T = embs.shape[0]   # total number of word-level embeddings\n",
    "\n",
    "if T <= 300:\n",
    "    idx = np.arange(T)\n",
    "else:\n",
    "    idx = np.linspace(0, T-1, 300, dtype=int)\n",
    "\n",
    "embs_ds = embs[idx]          # (300, 768)\n",
    "words_ds = [words[i] for i in idx]\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "embs_pca = pca.fit_transform(embs_ds)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embs_pca[:, 0], embs_pca[:, 1], s=12, alpha=0.7)\n",
    "\n",
    "# Label first 80 words\n",
    "num_labels = min(80, len(words_ds))\n",
    "for i in range(num_labels):\n",
    "    plt.text(\n",
    "        embs_pca[i, 0],\n",
    "        embs_pca[i, 1],\n",
    "        words_ds[i],\n",
    "        fontsize=8,\n",
    "        color=\"black\",\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "plt.title(\"PCA (downsampled to 300 words) â€“ First 80 words labeled\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be80aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Downsample words if the story is long\n",
    "max_words_for_viz = 300\n",
    "idxs = np.linspace(0, len(example_words) - 1,\n",
    "                   num=min(len(example_words), max_words_for_viz)).astype(int)\n",
    "\n",
    "viz_words = [example_words[i] for i in idxs]\n",
    "viz_vecs = finetuned_embeddings[idxs]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "vecs_2d = pca.fit_transform(viz_vecs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, w in enumerate(viz_words[:80]):  # label first 80 to avoid clutter\n",
    "    x, y = vecs_2d[i]\n",
    "    plt.scatter(x, y, s=5)\n",
    "    plt.text(x + 0.01, y + 0.01, w, fontsize=8)\n",
    "plt.title(f\"PCA with word labels (subset)\\nStory {example_story_id}\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b85295",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,        # good for 200 < n < 2000\n",
    "    learning_rate=200, \n",
    "    init='pca',           # MUCH better results\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # parallel threads (sklearn >=1.4)\n",
    ")\n",
    "\n",
    "emb2d_tsne = tsne.fit_transform(viz_vecs)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, w in enumerate(viz_words[:80]):  # label first 80 to avoid clutter\n",
    "    x, y = emb2d_tsne[i]\n",
    "    plt.scatter(x, y, s=5)\n",
    "    plt.text(x + 0.01, y + 0.01, w, fontsize=8)\n",
    "plt.title(\"t-SNE of BERT Embeddings\")\n",
    "plt.xlabel(\"Dim 1\")\n",
    "plt.ylabel(\"Dim 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05e3ee",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import downsample_word_vectors, make_delayed\n",
    "\n",
    "BASE_DIR = Path(\"/ocean/projects/mth250011p/shared/215a/final_project\")\n",
    "TEXT_PATH = BASE_DIR / \"data\" / \"raw_text.pkl\"\n",
    "\n",
    "BOLD_BASE = BASE_DIR / \"data\"\n",
    "SUBJECT_DIRS = {\n",
    "    2: BOLD_BASE / \"subject2\",\n",
    "    3: BOLD_BASE / \"subject3\",\n",
    "}\n",
    "BERT_EMB_PATH = Path(repo_root) / \"embeddings\" / \"bert_lora_finetuned\" / \"bert_lora_finetuned_word_embeddings.pkl\"\n",
    "\n",
    "# DataSequence (wordseqs)\n",
    "with open(TEXT_PATH, \"rb\") as f:\n",
    "    wordseqs = pickle.load(f)   # dict: story_id -> DataSequence\n",
    "\n",
    "print(\"wordseqs stories:\", list(wordseqs.keys())[:5])\n",
    "\n",
    "# BERT embedding\n",
    "with open(BERT_EMB_PATH, \"rb\") as f:\n",
    "    bert_emb = pickle.load(f)   # dict: story_id -> {..., \"embeddings\": (T,768)}\n",
    "\n",
    "print(\"bert_emb stories:\", list(bert_emb.keys())[:5])\n",
    "\n",
    "# check story id\n",
    "stories = sorted(set(wordseqs.keys()) & set(bert_emb.keys()))\n",
    "print(\"num stories:\", len(stories))\n",
    "stories[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee86fa5",
   "metadata": {},
   "source": [
    "### Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample_word_vectors\n",
    "word_vectors = {}\n",
    "for sid in stories:\n",
    "    embs = bert_emb[sid][\"embeddings\"]   # (num_words, 768)\n",
    "    word_vectors[sid] = embs.astype(\"float32\")\n",
    "\n",
    "downsampled_semanticseqs = downsample_word_vectors(\n",
    "    stories=stories,\n",
    "    word_vectors=word_vectors,\n",
    "    wordseqs=wordseqs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced94902",
   "metadata": {},
   "source": [
    "### Trim and delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cf7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"/ocean/projects/mth250011p/smazioud/\" / \"preprocessing\" / \"bert_lora_finetuned\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def preprocess_subject_streaming(subject_id, delays=None):\n",
    "    subj_dir = SUBJECT_DIRS[subject_id]\n",
    "    assert subj_dir.is_dir(), f\"{subj_dir} does not exist\"\n",
    "\n",
    "    missing_stories = []\n",
    "\n",
    "    for sid in stories:\n",
    "        ds = wordseqs[sid]\n",
    "        tr_times = ds.tr_times\n",
    "        stim_tr  = downsampled_semanticseqs[sid]\n",
    "\n",
    "        assert stim_tr.shape[0] == len(tr_times)\n",
    "\n",
    "        bold_path = subj_dir / f\"{sid}.npy\"\n",
    "        if not bold_path.is_file():\n",
    "            print(f\"[WARN] Subject {subject_id}: missing BOLD for story '{sid}', skipping.\")\n",
    "            missing_stories.append(sid)\n",
    "            continue\n",
    "\n",
    "        bold = np.load(bold_path)\n",
    "\n",
    "        n_stim = stim_tr.shape[0]\n",
    "        n_bold = bold.shape[0]\n",
    "\n",
    "        if n_stim < n_bold:\n",
    "            print(f\"[WARN] {sid}: stim shorter than bold, skipping.\")\n",
    "            missing_stories.append(sid)\n",
    "            continue\n",
    "\n",
    "        # TR trimming to match BOLD length\n",
    "        diff = n_stim - n_bold\n",
    "        drop_start = diff // 3 if diff > 0 else 0\n",
    "        drop_end = diff - drop_start if diff > 0 else 0\n",
    "\n",
    "        stim_trim = stim_tr[drop_start : n_stim - drop_end]\n",
    "\n",
    "        if stim_trim.shape[0] != n_bold:\n",
    "            print(f\"[WARN] {sid}: mismatch after trim, skipping.\")\n",
    "            missing_stories.append(sid)\n",
    "            continue\n",
    "\n",
    "        # delay\n",
    "        if delays is None:\n",
    "            raise ValueError(\"delays must be provided if only X_delayed is saved.\")\n",
    "\n",
    "        X_delayed = make_delayed(stim_trim, delays=delays)\n",
    "        X_delayed = X_delayed.astype(\"float32\")\n",
    "\n",
    "        bold = bold.astype(\"float32\")\n",
    "\n",
    "        result = {\n",
    "            \"X_delayed\": X_delayed,   # (N, 768 * len(delays))\n",
    "            \"bold\": bold,             # (N, n_vox)\n",
    "        }\n",
    "\n",
    "        out_file = OUT_DIR / f\"subject{subject_id}_{sid}_Xdelayed.pkl\"\n",
    "        with open(out_file, \"wb\") as f:\n",
    "            pickle.dump(result, f)\n",
    "\n",
    "        print(\n",
    "            f\"[SAVE] Subject {subject_id}, story {sid}: \"\n",
    "            f\"X_delayed {X_delayed.shape}, bold {bold.shape}, saved\"\n",
    "        )\n",
    "\n",
    "        del bold, stim_trim, X_delayed, result\n",
    "\n",
    "    if missing_stories:\n",
    "        print(f\"\\n[INFO] Subject {subject_id} skipped stories:\")\n",
    "        for s in missing_stories:\n",
    "            print(\"  -\", s)\n",
    "    else:\n",
    "        print(f\"\\n[INFO] Subject {subject_id}: all stories processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = [1,2,3,4]\n",
    "preprocess_subject_streaming(2, delays=delays)\n",
    "preprocess_subject_streaming(3, delays=delays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
